title: "Quickstart"
description: "Launch EventDBX locally, define a schema, mint tokens, and replicate a domain in minutes."
---

EventDBX ships as a single CLI named `dbx`. You can run everything with `npx`, but installing globally keeps the command available everywhere. Follow these six steps to go from a clean machine to a replicated domain with a working aggregate.

<Steps>

<Step title="Start the server">

```bash
npm install eventdbx -g
dbx start --foreground
```

- Omit `--foreground` to run as a daemon.
- Override storage with `--data-dir <path>` (defaults to `$HOME/.eventdbx`).
- Pick a validation mode with `--restrict=<off|default|strict>`; `default` enforces a schema when one exists.

</Step>

<Step title="Switch domains (optional)">

```bash
dbx checkout -d herds
```

- The default domain stores data under `<data_dir>/domains/default`.
- Domain names are case-insensitive, alphanumeric, and may include `-` or `_`.
- Rerunning checkout against the current domain is a no-op, so you can script context switches freely.

</Step>

<Step title="Define a schema">

```bash
dbx schema create person \
  --events person_created,person_updated \
  --snapshot-threshold 100
```

Schemas live in `~/.eventdbx/data/schemas.json` (or your chosen `data_dir`). Inspect one at any time:

```bash
dbx schema person
```

```json
{
  "person": {
    "aggregate": "person",
    "snapshot_threshold": null,
    "events": {
      "person_created": { "fields": ["first_name", "last_name"] },
      "person_updated": { "fields": [] }
    },
    "column_types": {
      "email": { "type": "text", "required": true, "format": "email" },
      "name": { "type": "text", "rules": { "length": { "min": "1", "max": "64" } } }
    }
  }
}
```

Use schemas to lock fields, hide payload slices, or freeze writes entirely (`locked: true`).

</Step>

<Step title="Issue a token">

```bash
dbx token generate --group admin --user jane --expiration 3600
```

Tokens are signed with an Ed25519 key pair defined under `[auth]` in `config.toml`. Keep the private key secret and distribute the public key to services that validate tokens.

</Step>

<Step title="Append events">

```bash
dbx aggregate apply person p-002 person_updated \
  --field name="Jane Doe" \
  --field status=active
```

- When the server is running, the CLI proxies writes through the control socket; otherwise it writes to the local RocksDB store.
- Filter and inspect history at any time:

```bash
dbx events --filter 'payload.status = "active"' --sort created_at:desc --take 5
```

Stream a single event as JSON via `dbx events <snowflake_id> --json`.

</Step>

<Step title="Replicate or sync domains">

```bash
dbx checkout -d remote1 \
  --remote 10.0.0.42:6363 \
  --token "$(cat ~/.eventdbx/replica.token)"
```

Push schemas first to keep validation consistent:

```bash
dbx push schema remote1
dbx push remote1 --aggregate ledger --id ledger-001
```

Pull data back down with the same integrity checks:

```bash
dbx pull remote1 --aggregate invoice
```

Need automation? `dbx watch remote1 --mode bidirectional --interval 120 --background` runs forever (or once with `--run-once`), respects concurrency flags, and exposes state via `dbx watch status <domain>`.

</Step>

</Steps>

## What to explore next

- **Snapshot thresholds**: Omit `--snapshot-threshold` to inherit `config.toml`. Use `dbx aggregate snapshot` for manual checkpoints.
- **Staging events**: `dbx aggregate apply --stage` queues writes in `.eventdbx/staged_events.json`. Commit them together with `dbx aggregate commit`.
- **Verification**: `dbx aggregate verify` recomputes the Merkle root for an aggregate; mismatches point to tampering or divergent history.

<Note>Every CLI command accepts `--config <path>` if you need to target an alternate configuration file.</Note>
